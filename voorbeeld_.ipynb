{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voorbeeld .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmaVanPuyenbr/test/blob/main/voorbeeld_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL9WYE8v3xLM"
      },
      "source": [
        "**Voorbeeld prof**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhHsTuxX3l03"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IuWiZOM3f03"
      },
      "source": [
        "def splitData(dataX, dataY):\n",
        "    trainX, testX, trainY, testY = train_test_split(dataX, dataY,test_size= 0.2,shuffle=True) # added shuffle=True \n",
        "    return trainX, testX, trainY, testY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDqSljYk3b_5"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model\n",
        "\n",
        "class RandomClassificationModel:\n",
        "    \"\"\"\n",
        "    Random classification model: \n",
        "        - generates random labels for the inputs based on the class distribution observed during training\n",
        "        - assumes an input can have multiple labels\n",
        "    \"\"\"\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Adjusts the class ratio variable to the one observed in y. \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: list of arrays - n x (height x width x 3)\n",
        "        y: list of arrays - n x (nb_classes)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "        \"\"\"\n",
        "     \n",
        "        trainX, testX, trainY, testY = splitData(X, y)\n",
        "\n",
        "        # Add our data-augmentation parameters to ImageDataGenerator\n",
        "        train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "        # Note that the validation data should not be augmented!\n",
        "        test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "        # Flow training images in batches of 20 using train_datagen generator\n",
        "        train_generator = train_datagen.flow(trainX, batch_size = 20, class_mode = 'categorical', target_size = (224, 224))\n",
        "\n",
        "        # Flow validation images in batches of 20 using test_datagen generator\n",
        "        validation_generator = test_datagen.flow( testX,  batch_size = 20, class_mode = 'categorical', target_size = (224, 224))\n",
        "\n",
        "        \n",
        "        base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
        "                            include_top = False, # Leave out the last fully connected layer\n",
        "                            weights = 'imagenet'\n",
        "                            )\n",
        "        \n",
        "        for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "        x = layers.Flatten()(base_model.output)\n",
        "        x = layers.Dense(1024, activation='relu')(x)\n",
        "        x = layers.Dropout(0.25)(x)\n",
        "        x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n",
        "\n",
        "        inc_history = model.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)\n",
        "\n",
        "        print(inc_history)\n",
        "        return self\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts for each input a label.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: list of arrays - n x (height x width x 3)\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        y_pred: list of arrays - n x (nb_classes)\n",
        "        \"\"\"\n",
        "        np.random.seed(0)\n",
        "        return [np.array([int(np.random.rand() < p) for p in self.distribution]) for _ in X]\n",
        "    \n",
        "    def __call__(self, X):\n",
        "        return self.predict(X)\n",
        "    \n",
        "model = RandomClassificationModel()\n",
        "model.fit(train_df[\"img\"], train_df[labels])\n",
        "test_df.loc[:, labels] = model.predict(test_df[\"img\"])\n",
        "test_df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBMNRymd3z36"
      },
      "source": [
        "**Voorbeeld maarten**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_NGvR-332LP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vh33iYqyoEw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, MaxPooling2D, BatchNormalization, Conv2D, Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "import cv2\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEwAZhobhuBN"
      },
      "source": [
        "class MobileNetV2_TransferModel:\n",
        "    \"\"\"\n",
        "    MobileNetV2_TransferModel: \n",
        "        - Transfer learning with a pre-trained model trained on ImageNet dataset\n",
        "          The top layer of the network is removed, and new layers are added and trained to fit our data.\n",
        "        - 'fit': trains top layer of the network. Steps before training the model: prepare data, split train-validate and preprocess\n",
        "        - 'predict': predict on unseen test set.\n",
        "        - assumes an input can have multiple labels\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self, X, y, training=True):\n",
        "        \"\"\"\n",
        "        Trains the toplayers of the pre-trained MobileNetV2 network.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: list of arrays - n x (height x width x 3)\n",
        "        y: list of arrays - n x (nb_classes)\n",
        "        training: boolean indicating whether or not training must be performed. If False, the model was already trained \n",
        "        and stored and will be imported.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "        \"\"\"\n",
        "        \n",
        "        # prepare data\n",
        "        X = X.apply(lambda x: cv2.resize(x,(224,224)))  # resize all images to same size\n",
        "        X = np.stack(X,0)   # make numpy array with correct dimensions (N,X,Y,Z)\n",
        "        y = np.array(y)     # dataframe to array\n",
        "\n",
        "        # split train data into train-validate\n",
        "        X_train, x_val, y_train, y_val = splitData(X, y)\n",
        "\n",
        "        # preprocess \n",
        "        X_train = X_train/255.0  # normalize\n",
        "        x_val = x_val/255.0\n",
        "\n",
        "        X_train_mean = np.mean(X_train, axis=0) # mean substraction\n",
        "        X_train = X_train - X_train_mean\n",
        "        x_val = x_val - X_train_mean \n",
        "        self.X_train_mean = X_train_mean\n",
        "\n",
        "        # checkpoint directory\n",
        "        checkpoint_filepath = '/content/DATA/MyDrive/DATA/train/MobileNetV2_TransferModel.h5'\n",
        "\n",
        "        if training:\n",
        "\n",
        "          # MobileNetV2 basemodel (frozen)\n",
        "          base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
        "          base_model.trainable = False\n",
        "\n",
        "          # add layers to frozen MobileNetV2\n",
        "          model = Sequential([\n",
        "            base_model,\n",
        "            GlobalAveragePooling2D(),\n",
        "            Dense(20, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile\n",
        "          model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])  # accuracy? or use f1-score?\n",
        "          # data augmentation\n",
        "          train_datagen = ImageDataGenerator(rotation_range=90, width_shift_range=0.2              \n",
        "                                        ,height_shift_range=0.2, shear_range=0.2,zoom_range=0.2\n",
        "                                        ,fill_mode=\"nearest\", horizontal_flip=True)\n",
        "\n",
        "          train_datagen.fit(X_train)\n",
        "\n",
        "          # checkpoint\n",
        "          save_best = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=0, \n",
        "                                        save_best_only=True,save_weights_only=False, mode='max', save_freq=\"epoch\")\n",
        "\n",
        "          # training the classifier\n",
        "          history = model.fit(train_datagen.flow(X_train, y_train, batch_size=32),\n",
        "                                  validation_data=(x_val, y_val),                      \n",
        "                                  epochs=50, verbose=1, workers=4, shuffle=True, callbacks=[save_best])\n",
        "          self.model = model\n",
        "\n",
        "        else:\n",
        "          # load saved model\n",
        "          self.model = load_model(checkpoint_filepath)\n",
        "\n",
        "          return self\n",
        "        \n",
        "    def predict_(self, X):\n",
        "        \"\"\"\n",
        "        Predicts for each input a label.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: list of arrays - n x (height x width x 3)\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        y_pred: array - n x nb_classes\n",
        "        \"\"\"\n",
        "        # prepare data\n",
        "        print(X.shape)\n",
        "        X = X.apply(lambda x: cv2.resize(x,(224,224)))  # resize all images to same size\n",
        "        X = np.stack(X,0)   # make numpy array with correct dimensions (N,X,Y,Z)\n",
        "\n",
        "        # preprocess\n",
        "        X = X/255.0\n",
        "        X = X - self.X_train_mean\n",
        "\n",
        "        # predict\n",
        "        y_pred = self.model.predict(X)\n",
        "        return y_pred\n",
        "\n",
        "    def __call__(self, X):\n",
        "        return self.predict(X)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}